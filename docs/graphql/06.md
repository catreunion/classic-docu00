---
sidebar_position: 6
---

# From monolithic to federated

Problems with monolithic GraphQL schema

friction when trying to grow and evolve their graph when the monolithic schema becomes too big to handle

Lack of focus on domain responsibilities caused by the presence of unrelated types and fields

Difficulty navigating to the information they need in a constantly growing schema file

Merge conflicts caused by modifying the same schema file as multiple other individuals and teams

Airlock, a space travel app to book a trip to new, exciting, sometimes-fictional places in the vast universe?

find listings that meet your dates of choice and the number of beds you'll need. Learn what each place is all about and what amenities it offers, and if you're interested, you can book your stay in one click (provided you have enough space credits in your wallet of course)!

If you're looking to rent out your own space suite, you can do that with Airlock too! Add your listing to the platform with all the necessary details and start managing your bookings. After each stay, guests and hosts will leave honest ratings and reviews about each other.

## Airlock's evolution story

Soon enough, the small unassuming app transformed into an unwieldy monolith. The developer experience is degrading as friction starts to creep in - schema changes and improvements are met with merge conflicts, inconsistencies and duplicated information. It's becoming difficult to navigate the large schema file! New features and bug fixes are taking longer to deploy.

an intimidatingly huge monster representing the monolith graph

it more closely resembles a big monolith monster with many different business domains represented as types, queries, and mutations all contained in a single humongous .graphql file!

üë©üèΩ‚ÄçüöÄ The Accounts Team says:

"We're in charge of all things related to users, accounts, and user profiles! We think it's a fairly small scope to work within, so it's been a pain having to sift through all the other business domains in the schema that don't involve our intended changes."

üë©üèΩ‚Äçüè´ The Listings Team says:

"We deal with all the cool space rentals in Airlock: their information, amenities, and linking them back to a profile (which the Accounts team is responsible for). We definitely own a big chunk of what's in the schema right now and we make a lot of changes with new features and improvements! Oftentimes, we have merge conflicts with other teams."

all of the schema's types, fields, and behavior will still be preserved and working as usual.

First and foremost, we want to make sure that throughout this process, the web app client doesn't experience any issues and that queries continue to work as normal!

Here are the high-level steps for our migration plan:

1. convert the monolith GraphQL server into a subgraph server, which we'll run on a different port.

2. create a router running on the monolith's original port. The router will be connected to the schema registry and will handle all of the same queries that were previously being sent to the monolith server.

3. slit off small chunks of our single monolith subgraph into new domain-specific subgraphs. This will take several steps, which we'll explain in more detail later on.

the Strangler Fig approach - a migration technique that involves incrementally replacing an old system with new components until the old system is "strangled" and can be completely removed.

A simple schema can potentially evolve into a big, intimidating schema that is difficult to navigate and work with for different teams

Avoid any issues with the client by following a migration plan that swaps the original monolith server with the router.

# test

```bash title="Repo from apollographql.com"
git clone https://github.com/apollographql/odyssey-voyage-II-server

# navigate to monolith/
cd odyssey-voyage-II-server/monolith/

# install
yarn

# start up all locally hosted services by running a script
# npm run launch
yarn launch
```

For simplicity's sake, all locally-run services are located in the same repo. In a real-world scenario, each of these is more likely to be located in a different repo and owned and maintained by a different team.

4000 monolith server
blue 4011 Accounts REST API
pink 4010 Listings REST API
green Local Bookings SQLite database
Local Reviews SQLite database
Hosted Payments REST AP

Each message is prefixed with a color-coded label identifying which service or server the message belongs to.

AccountsAPI: a RESTDataSource that connects to the accounts service
ListingsAPI: a RESTDataSource that connects to the listings service
BookingsDb: a custom DataSource class that connects to the bookings service using Sequelize
ReviewsDb: a custom DataSource class that connects to the reviews service using Sequelize
PaymentsAPI: a RESTDataSource that connects to the payments service

`schema.graphql`, `resolvers.js`

```bash title="monolith/"
# start up the monolith GraphQL server
# npm start
yarn start
```

nodemon : any changes we save to our code will also automatically restart the server

the listingAmenities field. Then for each amenity, we want to retrieve its category and name.

```graphql title="a query test"
<!-- retrieve all the amenities that a listing can provide -->
query GetAllAmenities {
  listingAmenities {
    category
    name
  }
}
```

## Publishing the graph to Studio

[Apollo Studio](https://studio.apollographql.com/)

Classic Graphs --> New Classic Graph --> Graph Architecture : Monolith --> click **Local Schema** in the modal --> copy the entire schema in `monolith/schema.graphql` --> paste into the text area --> Upload --> run the query test again --> set the Endpoint to http://localhost:4000 --> Save

APOLLO_KEY and APOLLO_GRAPH_REF

environment variables should never be committed to version control.

.gitignore file which specifies that the .env file should be ignored when committing code changes to a repository.

## Setting up the Rover CLI

Rover is Apollo's official command line interface, and plays a central role in every supergraph.

```bash title="project root"
# re-authenticate Rover with the correct APOLLO_KEY
rover config auth
```

```bash title="outside of the server repo"
# clone the frontend repo
git clone https://github.com/apollographql/odyssey-voyage-II-client

cd odyssey-voyage-II-client
yarn
yarn start
```

You can use Airlock as either a guest or a host by clicking Log In on the top right and selecting the appropriate option. We also have additional account login options for you to choose from, but generally we'll stick with the main Guest or Host buttons.

To switch to a different account after logging in, click the profile picture on the top right of the page and "Log out".

# test

1. create a single large subgraph with the exact same schema as the monolith, and run it on a different port.

2. Publish the 1st subgraph to the Apollo registry

One terminal should be running npm start, to start the monolith server on port 4000.

```bash title="monolith/"
# stop the monolith GraphQL server

# install the @apollo/subgraph package
yarn add @apollo/subgraph
```

```js title="monolith/index.js"
const { buildSubgraphSchema } = require("@apollo/subgraph")

// ApolloServer is known as a constructor
// define a schema property in the constructor
const server = new ApolloServer({
  schema: buildSubgraphSchema({
    typeDefs,
    resolvers
  })
})

const port = 4001
```

```graphql title="monolith/schema.graphql"
extend schema @link(url: "https://specs.apollo.dev/federation/v2.0", import: ["@key"])
```

```bash title="monolith/"
# start up the monolith GraphQL server
# npm start
yarn start
```

go to http://localhost:4001 using Firefox / Google Chrome

```graphql title="test"
query GetAllAmenities {
  listingAmenities {
    category
    name
  }
}
```

## Publishing our subgraph

go to [Apollo Studio](https://studio.apollographql.com/)

```bash title="template"
rover subgraph publish <APOLLO_GRAPH_REF> \
  --schema <SCHEMA_FILE_PATH> \
  --name <SUBGRAPH_NAME> \
  --routing-url <SERVER_URL>
```

```bash title="root + new terminal window"
rover subgraph publish <APOLLO_GRAPH_REF> \
  --schema ./monolith/schema.graphql \
  --name monolith \
  --routing-url http://localhost:4001 \
```

```text title="error message from Apollo"
error[E007]: The graph `[APOLLO_GRAPH_REF]` is a non-federated graph.
This operation is only possible for federated graphs.
```

```bash title="root directory of backend servers"
# convert the existing graph into a supergraph
‚ùØ rover subgraph publish <APOLLO_GRAPH_REF> \
  --schema ./monolith/schema.graphql \
  --name monolith \
  --routing-url http://localhost:4001 \
  --convert

Publishing SDL to odyssey-voyage-II-bvu1tw@current (subgraph: monolith) using credentials from the default profile.
A new subgraph called 'monolith' was created in <APOLLO_GRAPH_REF>
The supergraph schema for <APOLLO_GRAPH_REF> was updated, composed from the updated 'monolith' subgraph
Monitor your schema delivery progression on studio: https://studio.apollographql.com/graph/odyssey-voyage-II-bvu1tw/launches/3e9479e9-a4ec-484c-8809-259abe623071?variant=current
```

Apollo Studio

We set up the monolith subgraph to use port 4001 because, as we outlined in our migration plan, we want the router to take over port 4000. (Don't worry - we haven't gotten there yet!) This way, the client doesn't need to make any changes to communicate with the router.

Create a router running on the monolith's original port. The router will be connected to the schema registry and will handle all of the same queries that were previously being sent to the monolith server. It ensures that nothing changes about how the client makes requests.

Start to split off small chunks of our single monolith subgraph into new domain-specific subgraphs. This will take several steps, which we'll explain in more detail later on.

# test

set up the router to run on the original server port (port 4000). Before we jump into the code to do that, let's take a look at how we're going to ensure that both the router and the monolith subgraph are set up to handle authentication and authorization correctly

Review how auth works in Airlock's monolithic architecture

Learn how to propagate authorization headers from the router to its subgraphs

Airlock has two types of users: hosts and guests. Each type of user can perform different kinds of actions.

When logged in as a host, you can:

- create listings

- manage bookings for your listings

- write reviews about guests

When logged in as a guest, you can:

- book places to stay

- write reviews about the location and the host

- manage your space credits

Currently, guest users are not allowed to create listings, and host users are not allowed to book places to stay.

With these **business rules**, our Airlock GraphQL API needs to control which users can see and interact with certain fields in the graph. This is where authentication and authorization come in.

**Authentication** is determining whether a given user is logged in, and subsequently determining which user someone is. (They are who they say they are.)

**Authorization** is determining what a given user has permission to do or see. (They're allowed to do what they're trying to do.)
Note: First time working with auth? Check out the Authentication & Authorization side quest for a closer look at how to verify user logins and permissions.

In Airlock, we're using HTTP headers, specifically the Authorization header with a Bearer token to provide our user credentials. The header looks something like this:

Authorization: Bearer user-1

Once the GraphQL server receives the incoming client operation, it retrieves the token from the request header and attempts to authenticate the user using the accounts service. After a successful authentication, the accounts service returns an object with `userId` and `userRole`, which the GraphQL server then adds to the context object that's available to every resolver.

Airlock uses **field-level authorization**. That means each resolver checks whether the logged-in user has permission to access that part of the graph. They do so using the `userId` and `userRole` properties from the context object.

Auth in a supergraph

In the original monolithic architecture, the GraphQL server received authorization headers from the client, did some logic to pull out the user information needed, then passed this information to its resolvers through the context object.

In the supergraph architecture, the story remains similar. The router will receive authorization headers from the client, then pass this information to its subgraphs. Each subgraph will do the same logic to pull out the user information and pass it over to their resolvers.

How does the router pass this information to its subgraphs? And what does the subgraph need to do to pass it to its resolvers? Let's dive into these questions and answer them in the story of "Auth in a supergraph"!

Note: We're going to focus on the story where the app uses HTTP headers and field-level authorization. Some parts of the story may change if your application uses different auth methods.

Authenticating the user
The story starts in the same way our GraphQL query journey does: with a request from the client to the server. This particular request includes an Authorization header that contains the logged-in user credentials.

HTTP request with auth header is sent from the browser to the router
The router receives this request and starts to create its **query plan**, using the supergraph schema as a reference to determine which subgraph to query for a particular field.

The router builds a query plan to resolve the request
Next, the router executes the query plan. It starts at the top, sending a request to the subgraph. Included with this request is the Authorization header that came from the client!

But how does the router know it should be passing along that header? It's all in the configuration!

Sending HTTP headers to subgraphs

When we start up the router, we have the option of passing in a configuration file, using the `--config` flag. This allows us to customize the router in many ways, such as configuring CORS (which we saw in Voyage I for permitted request origins), introspection, and HTTP headers

Using the config file, we'll tell the router to send the Authorization header to its subgraphs with every request. We'll see this configuration in action in the next lesson. customizing which headers the router can receive and where to send them.

The config file provides instructions for which headers to send to the subgraphs

Over to the subgraph

When the subgraph receives the request from the router, it accesses the Authorization header from the request and attempts to authenticate the user.

If the attempt is unsuccessful, the subgraph stops and sends an AuthenticationError back to the router, which then sends it right back to the client.

The subgraph attempts to authenticate the user, returning an Authentication Error to the router if unsuccessful
If the authentication is successful, then the subgraph puts together an object containing user information and makes it available in its context. This user information object can be shaped in whatever way is going to be most useful to the subgraph's resolvers, and passed through the context object.

The subgraph resolves the operations the same way as any other GraphQL server: they use their resolvers and data sources to retrieve and populate the requested data. And they can use the user information in the context object to check against the specific business rules that guard their field and who has access to it!

The subgraph resolves the operation using its resolver functions and data sources

Back to the router

The subgraph sends back the requested data to the router, and the router continues with its query plan, eventually combining all those responses into a single JSON object.

Finally, the router sends the final JSON object back to the client. And that's the end of our operation's journey!

A doodle detailing the journey of authentication in a supergraph in its entirety

Which of the following options can be included as part of a router's config file?

In Airlock, the client sends its request to the router, with the addition of an HTTP header called Authorization, which contains the current user's auth token.

The router can be customized with a configuration file, to pass along HTTP headers to its subgraphs.

The router passes the user's auth token to the subgraph, which checks whether or not the token is valid for login.

If the login is unsuccessful, the subgraph throws an AuthenticationError and sends it back to the router.

If the login is successful, the subgraph adds the current user's information to its context object, which is accessible by its resolvers for field-level authorization.

We've learned how to handle auth in a supergraph, so let's put everything together and implement this in code!

Let's put together what we've learned about how to implement auth in a supergraph

# test

Configure the router to pass HTTP headers to subgraphs

Set up the subgraph to receive the headers and authenticate the user

Test out a query that needs authentication and authorization using Apollo Studio

Diagram of step 2 of the migration plan. Step 2 is creating a router running on the original port that is connected to the registry.

‚úÖ Service check
Before moving on, let's make sure all of our processes are still running!

One terminal should be running npm start, to start the monolith subgraph server on port 4001.

Another should be running npm run launch, to start our services in the monolith directory on ports 4010 and 4011.

```bash title="router/"
# download and install the Apollo Router
curl -sSL https://router.apollo.dev/download/nix/latest | sh
```

move that file from the `monolith` directory into the `router` directory

```text title="router/"
üì¶ router
‚î£ üìÑ .env
‚î£ üìÑ config.yaml
‚îó üìÑ router
```

```yaml title="router/config.yaml"
# tell the router to send the Authorization header to its subgraphs with every request.
headers:
  all:
    request:
      - propagate:
          named: "Authorization"
include_subgraph_errors:
  all: true # Propagate errors from all subgraphs
```

subgraph errors are omitted from router logs for security reasons. The setting we're referencing in the configuration file, include_subgraph_errors, is a setting that will allow the router to share the details of any errors that occur as it communicates with subgraphs

‚úèÔ∏è Adding Authorization headers

The `headers` key is where we set all of our rules for HTTP headers.

`all` indicates that the rules nested underneath will apply to all the subgraphs. We could specify which ones using the subgraphs key, but we know that for Airlock we'll need to pass it to all of them.

`request` specifies that the included headers should apply to requests the router receives.

Finally, we want to pass the `Authorization` header to all the subgraphs, so we'll use the propagate key, then indicate the name of the header with named: 'Authorization'.

With our router all set up to pass these authentication headers to its subgraphs, let's make sure the subgraph is ready to receive these headers and pass them along to its own resolvers!

Setting up the subgraph for auth

when the monolith subgraph was a standalone GraphQL server? Well, it was already taking in the Authorization header, retrieving the user token and authenticating it using the accounts service!

```js title="monolith/index.js"
context: async ({ req }) => {
  const token = req.headers.authorization || '';
  const userId = token.split(' ')[1]; // get the user name after 'Bearer '

  let userInfo = {};
  if (userId) {
    const { data } = await axios.get(`http://localhost:4011/login/${userId}`).catch((error) => {
      throw AuthenticationError();
    });

    userInfo = { userId: data.id, userRole: data.role };
  }

  return {
    ...userInfo,
    dataSources: {
      bookingsDb: new BookingsDataSource(),
      reviewsDb: new ReviewsDataSource(),
      listingsAPI: new ListingsAPI(),
      accountsAPI: new AccountsAPI(),
      paymentsAPI: new PaymentsAPI(),
    },
  };
},
```

With this logic already in place

Running the router with config

```bash title="router/"
APOLLO_KEY=<APOLLO_KEY> APOLLO_GRAPH_REF=<APOLLO_GRAPH_REF> ./router --config config.yaml
```

Remember port 4000 was where the original monolith GraphQL server was running? Now we've successfully replaced it with the router! Clients don't have to do anything extra to change their endpoints, they can keep querying as usual.

üë©üèΩ‚Äçüî¨ Testing the Authorization headers

Let's give it a try! We can head back over to the Explorer in Apollo Studio to test out a query for the router.

We'll try out a query that requires an authenticated and authorized user: retrieving a host's listings. This query needs you to be logged in as a host.

Using Explorer, let's build a query to retrieve a host's listings. For each listing, we'll ask for the title, costPerNight, description, photoThumbnail, numOfBeds, and locationType.

```
query GetHostListings {
  hostListings {
    title
    costPerNight
    description
    photoThumbnail
    numOfBeds
    locationType
  }
}
```

Let's run the query, and‚Ä¶ uh oh! We get back an AuthenticationError with no logged-in user üò±

After a brief moment of panic, let's think about what we're missing.

We've just set up the server-side handling of authorization headers, but we haven't actually sent those headers with our request! So our server is trying to authenticate the user sending the request, but it can't find them and it returns the appropriate error.

Let's go ahead and add those headers. In the bottom panel of the Explorer, open the **Headers** tab.

Click New header and set the header key as **Authorization**. Set the value as `Bearer user-1`. We know that user-1 is a host!

Authorization: Bearer user-1

For fun, let's check what happens if we ask for the exact same fields, but as a guest, like user-2. Change the value of the Authorization header to "Bearer user-2", then run the query.

We get a ForbiddenError that says only hosts have access to listings - we're logged in as a guest so that's great, our server is working as it's supposed to!

Diagram of step 2 of the migration plan, checked off and completed. Step 2 is creating a router running on the original port that is connected to the registry.

```yaml title="send the "airlock-cookie" header to all subgraphs"
headers:
  all:
    request:
      - propagate:
          named: "airlock-cookie"
```

In the above config.yaml file, what does the propagate key tell the router to do?

Key takeaways
To pass down authorization headers from the router to its subgraphs, we need to set up the router's config file.
In the config file, we can set the headers property and use the propagate property.
A subgraph can access the authorization (and other request) headers from the router through its ApolloServer constructor context property.
We can use Apollo Explorer's Headers panel to set authorization headers for our GraphQL request.
Up next
We've checked off another task in our migration plan, and we're ready to move on to split this subgraph even further.

ÁôºÁèæÊâìÂ∞ë‰∏ÄÂºµÂí≠ÂèØÁØÄÁúÅ‰∏âÂàÜÈêò„ÄÇ
https://youtu.be/hrJC0cX7dBE
