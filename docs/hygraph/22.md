---
sidebar_position: 22
---

# From monolithic to federated

Common problems that developers experience with a monolithic GraphQL schema

Developers experience a lot of friction when trying to grow and evolve their graph when the monolithic schema becomes too big to handle

Lack of focus on domain responsibilities caused by the presence of unrelated types and fields

Difficulty navigating to the information they need in a constantly growing schema file

Merge conflicts caused by modifying the same schema file as multiple other individuals and teams

modularize our graphs and scale faster

Airlock, a space travel app to book a trip to new, exciting, sometimes-fictional places in the vast universe?

find listings that meet your dates of choice and the number of beds you'll need. Learn what each place is all about and what amenities it offers, and if you're interested, you can book your stay in one click (provided you have enough space credits in your wallet of course)!

If you're looking to rent out your own space suite, you can do that with Airlock too! Add your listing to the platform with all the necessary details and start managing your bookings. After each stay, guests and hosts will leave honest ratings and reviews about each other.

## Airlock's evolution story

Diagram of Airlock's architecture showing one web client connected to the GraphQL server which in turn connects to multiple services

Soon enough, the small unassuming app transformed into an unwieldy monolith. The developer experience is degrading as friction starts to creep in - schema changes and improvements are met with merge conflicts, inconsistencies and duplicated information. It's becoming difficult to navigate the large schema file! New features and bug fixes are taking longer to deploy.

an intimidatingly huge monster representing the monolith graph

it more closely resembles a big monolith monster with many different business domains represented as types, queries, and mutations all contained in a single humongous .graphql file!

üë©üèΩ‚ÄçüöÄ The Accounts Team says:

"We're in charge of all things related to users, accounts, and user profiles! We think it's a fairly small scope to work within, so it's been a pain having to sift through all the other business domains in the schema that don't involve our intended changes."

üë©üèΩ‚Äçüè´ The Listings Team says:

"We deal with all the cool space rentals in Airlock: their information, amenities, and linking them back to a profile (which the Accounts team is responsible for). We definitely own a big chunk of what's in the schema right now and we make a lot of changes with new features and improvements! Oftentimes, we have merge conflicts with other teams."

all of the schema's types, fields, and behavior will still be preserved and working as usual.

First and foremost, we want to make sure that throughout this process, the web app client doesn't experience any issues and that queries continue to work as normal!

Here are the high-level steps for our migration plan:

1. convert the monolith GraphQL server into a subgraph server, which we'll run on a different port.

2. create a router running on the monolith's original port. The router will be connected to the schema registry and will handle all of the same queries that were previously being sent to the monolith server.

3. slit off small chunks of our single monolith subgraph into new domain-specific subgraphs. This will take several steps, which we'll explain in more detail later on.

the Strangler Fig approach - a migration technique that involves incrementally replacing an old system with new components until the old system is "strangled" and can be completely removed.

A simple schema can potentially evolve into a big, intimidating schema that is difficult to navigate and work with for different teams

Avoid any issues with the client by following a migration plan that swaps the original monolith server with the router.

#

Learn how the backend GraphQL server is organized
Learn what services and data sources the server uses
Have both the server and client running on our local machine
Set up the graph on Apollo Studio
Set up the Rover CLI

```bash title="Repo from apollographql.com"
git clone https://github.com/apollographql/odyssey-voyage-II-server

# navigate to monolith/
cd odyssey-voyage-II-server/monolith/

# install
yarn

# start up all the services hosted locally
# npm run launch
# run the launch script
yarn launch
```

For simplicity's sake, all locally-run services are located in the same repo. In a real-world scenario, each of these is more likely to be located in a different repo and owned and maintained by a different team.

4000 monolith server
blue 4011 Accounts REST API
pink 4010 Listings REST API
green Local Bookings SQLite database
Local Reviews SQLite database
Hosted Payments REST AP

We'll see a bunch of output come up in the terminal. Each message is prefixed with a color-coded label identifying which service or server the message belongs to. The accounts, listings, bookings, and reviews services should now be running!

We won't be modifying anything in the services directory!

Data sources

Our GraphQL server uses data sources to connect and communicate with each service

AccountsAPI: a RESTDataSource that connects to the accounts service
ListingsAPI: a RESTDataSource that connects to the listings service
BookingsDb: a custom DataSource class that connects to the bookings service using Sequelize
ReviewsDb: a custom DataSource class that connects to the reviews service using Sequelize
PaymentsAPI: a RESTDataSource that connects to the payments service

`schema.graphql`, `resolvers.js`

```bash title="monolith/"
# start up the monolith GraphQL server
# npm start
yarn start
```

nodemon : any changes we save to our code will also automatically restart the server

the listingAmenities field. Then for each amenity, we want to retrieve its category and name.

```graphql title="a query test"
<!-- retrieve all the amenities that a listing can provide -->
query GetAllAmenities {
  listingAmenities {
    category
    name
  }
}
```

## Publishing the graph to Studio

[Apollo Studio](studio.apollographql.com)

Classic Graphs --> New Classic Graph --> Graph Architecture : Monolith --> click **Local Schema** in the modal --> copy the entire schema in `monolith/schema.graphql` --> paste into the text area --> Upload --> run the query test again --> set the Endpoint to http://localhost:4000 --> Save

APOLLO_KEY and APOLLO_GRAPH_REF

environment variables should never be committed to version control.

.gitignore file which specifies that the .env file should be ignored when committing code changes to a repository.

## Setting up the Rover CLI

Rover is Apollo's official command line interface, and plays a central role in every supergraph.

```bash title="project root"
# re-authenticate Rover with the correct APOLLO_KEY
rover config auth
```

```bash title="outside of the server repo"
# clone the frontend repo
git clone https://github.com/apollographql/odyssey-voyage-II-client

cd odyssey-voyage-II-client
yarn
yarn start
```

You can use Airlock as either a guest or a host by clicking Log In on the top right and selecting the appropriate option. We also have additional account login options for you to choose from, but generally we'll stick with the main Guest or Host buttons.

To switch to a different account after logging in, click the profile picture on the top right of the page and "Log out".

#

tackle the first step for migrating our monolith app into a supergraph. We'll start by converting the monolith server into a single subgraph, which will run on a different port.

Review how to create a subgraph using Apollo Server

Publish our first subgraph to the Apollo registry

Diagram of the migration plan step 1. Step 1 was to create a single large subgraph with the exact same schema as the monolith, and run it on a different port. This single subgraph will be published to the registry.

One terminal should be running npm start, to start the monolith server on port 4000.
Another terminal should be running npm run launch, to start our services in the monolith directory on ports 4010 and 4011.
‚úèÔ∏è Importing packages

stop the monolith server

```bash title="monolith"
npm install @apollo/subgraph
```

```js title="monolith/index.js"
const { buildSubgraphSchema } = require("@apollo/subgraph")

// ApolloServer is known as a constructor
// define a schema property in the constructor
const server = new ApolloServer({
  schema: buildSubgraphSchema({
    typeDefs,
    resolvers
  })
})

const port = 4001
```

```graphql title="monolith/schema.graphql"
extend schema @link(url: "https://specs.apollo.dev/federation/v2.0", import: ["@key"])
```

```bash title="monolith"
npm start
```

go to http://localhost:4001

```graphql title="test"
query GetAllAmenities {
  listingAmenities {
    category
    name
  }
}
```

## Publishing our subgraph

```bash title="template"
rover subgraph publish <APOLLO_GRAPH_REF> \
  --schema <SCHEMA_FILE_PATH> \
  --name <SUBGRAPH_NAME> \
  --routing-url <SERVER_URL>
```

```bash title="root + new terminal window"
rover subgraph publish <APOLLO_GRAPH_REF> \
  --schema ./monolith/schema.graphql \
  --name monolith \
  --routing-url http://localhost:4001 \
```

```text
error[E007]: The graph `[APOLLO_GRAPH_REF]` is a non-federated graph.
This operation is only possible for federated graphs.
```

```bash title="convert the existing graph into a supergraph"
rover subgraph publish <APOLLO_GRAPH_REF> \
  --schema ./monolith/schema.graphql \
  --name monolith \
  --routing-url http://localhost:4001 \
  --convert
```

Apollo Studio

Which of these does the migration plan enable us to do when converting the monolith into a supergraph?

We set up the monolith subgraph to use port 4001 because, as we outlined in our migration plan, we want the router to take over port 4000. (Don't worry - we haven't gotten there yet!) This way, the client doesn't need to make any changes to communicate with the router.

Create a router running on the monolith's original port. The router will be connected to the schema registry and will handle all of the same queries that were previously being sent to the monolith server.

Start to split off small chunks of our single monolith subgraph into new domain-specific subgraphs. This will take several steps, which we'll explain in more detail later on.
